<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>StyleBooth: Image Style Editing with Multimodal Instruction</title>
    <link href="./public/style.css" rel="stylesheet">
  </head>

  <body>
      <div class="content">
        <h1><strong>
          StyleBooth: Image Style Editing with Multimodal Instruction
        </strong></h1>
        <p id="authors">
          <span><a href=""></a></span>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Zhen Han</a><sup style="margin-left: -7px;">1</sup>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Chaojie Mao</a><sup style="margin-left: -7px;">1</sup>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Zeyinzi Jiang</a><sup style="margin-left: -7px;">1</sup>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Yulin Pan</a><sup style="margin-left: -7px;">1</sup>
          <a href="" style="pointer-events: none; text-decoration:none; color: black;">Jingfeng Zhang</a><sup style="margin-left: -7px;">1</sup>
          <br><br>
          <span style="font-size: 22px;"><sup>1</sup>Alibaba Group</span>
          <!-- <br> -->
          &nbsp;&nbsp;&nbsp;
        </p>
        <br>
         <video controls poster="public/videos/stylebooth_video_poster.jpg" style="width:100%">
            <source src="public/videos/stylebooth.mp4" type="video/mp4">
         </video>
        <br>
        <p style="text-align: center; font-size: 18px;">
          <em>
            StyleBooth is a unified style editing method supporting <strong>text-based</strong>, <strong>exemplar-based</strong> and <strong>compositional</strong> style editing.
          </em>
        </p>
        <p style="text-align: center; font-size: 20px;">
          <a href="https://openaccess.thecvf.com/content/ICCV2025W/HiGen/papers/Han_StyleBooth_Image_Style_Editing_with_Multimodal_Instruction_ICCVW_2025_paper.pdf" target="_blank">[Paper]</a>
          <a href="https://openaccess.thecvf.com/content/ICCV2025W/HiGen/supplemental/Han_StyleBooth_Image_Style_ICCVW_2025_supplemental.pdf" target="_blank">[Supp]</a>
          <a href="./public/bibtex.txt" target="_blank">[BibTeX]</a>
          <a href="https://modelscope.cn/models/iic/stylebooth/summary" target="_blank">[Model]</a>
          <a href="https://modelscope.cn/models/iic/stylebooth/summary" target="_blank">[Dataset]</a>
          <a href="https://github.com/modelscope/scepter/blob/main/docs/en/tasks/stylebooth.md" target="_blank">[Code Based on SCEPTER]</a>
        </p>
        <p style="text-align: center; font-size: 20px;">
          <a href="https://huggingface.co/spaces/modelscope/scepter_studio" target="_blank">[HuggingFace Demo]</a>
          <a href="https://www.modelscope.cn/studios/iic/scepter_studio/summary" target="_blank">[ModelScope Demo]</a>
        </p>
      </div>

      <div class="content">
        <h2 style="text-align: center;">Abstract</h2>
        <p>
            Given an original image, image editing aims to generate an image that align with the provided instruction. The challenges are to accept multimodal inputs as instructions and a scarcity of high-quality training data, including crucial triplets of source/target image pairs and multimodal (text and image) instructions. In this paper, we focus on image style editing and present <strong>StyleBooth</strong>, a method that proposes a comprehensive framework for image editing and a feasible strategy for building a high-quality style editing dataset. We integrate encoded textual instruction and image exemplar as a unified condition for diffusion model, enabling the editing of original image following <strong>multimodal instructions</strong>. Furthermore, by <strong>iterative style-destyle tuning and editing</strong> and usability filtering, the StyleBooth dataset provides content-consistent stylized/plain image pairs in various categories of styles. To show the flexibility of StyleBooth, we conduct experiments on diverse tasks, such as textbased style editing, exemplar-based style editing and compositional style editing. The results demonstrate that the quality and variety of training data significantly enhance the ability to preserve content and improve the overall quality of generated images in editing tasks.
        </p>
        <img src="./public/images/head.jpg" class="teaser-gif" style="width:100%">
      </div>

      <div class="content">
        <h2>Method</h2>
        <p style="font-size: 18px">
            We propose Multimodal Instruction, mapping the text input and exemplar image input into a same hidden space through a trainable matrix, which unifies vision and text instructions. The textual instruction templates are carefully designed, introducing undetermined identifiers like &quot;&lt;style&gt;&quot; and &quot;&lt;image&gt;&quot; to support multimodal inputs. To balance every style for compositional style editing, we conduct Scale Weights Mechanism on the hidden space embeddings. Editing is guided by multimodal features following the compositional instructions from different modalities at the same time.
        </p>
        <img class="summary-img" src="./public/images/method2.jpg" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2>High-Quality Style Editing Dataset</h2>
        <p style="font-size: 18px">
          Iterative Style-Destyle Tuning and Editing pipeline. Following a de-style editing, filtering, style tuning, stylize editing, filtering and de-style tuning steps, Iterative Style-Destyle Tuning and Editing leverages the image quality and usability.
        </p>
        <img class="summary-img" src="./public/images/method.jpg" style="width:100%;"><br><br>
        <p style="font-size: 18px">
            Generation samples of the intermediate and final image pairs in Iterative Style-Destyle Tuning and Editing. As the iteration process, image quality gets higher while key style features are gradually wiped off in the de-styled images. We show the style images and de-style results generated in 1st and 2nd de-styled phase and a plain image and results generated in 1st style phase.
        </p>
        <img class="summary-img" src="./public/images/dataset2.jpg" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2>Text-Based Style Editing</h2>
        <p style="font-size: 18px">
            Comparisons with instruction-based style editing baselines in Emu Edit benchmark. We show editing results of StyleBooth and 3 baselines. The results of StyleBooth are the most accurate in both style conveying and content preservation comparing to others, though some of the styles and instruction syntax are not contained in our tuning dataset.
        </p>
        <img class="summary-img" src="./public/images/comp1supp.jpg" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2>Exemplar-Based Style Editing</h2>
        <p style="font-size: 18px">
            Exemplar-based style editing with real world images. We present the results of 2 original images in the styles of 5 different art works. We use two original images: the David by Michelangelo and the Eiffel Tower, five style exemplars: an animate film stage photo, a Fauvism painting by Henri Matisse, a Cubism painting by Pablo Ruiz Picasso, a post-Impressionist painting by Georges Seurat and a pixel game character.
        </p>
        <img class="summary-img" src="./public/images/comp2supp.jpg" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2>Style Compositional Editing and Style Interpolation.</h2>
        <p style="font-size: 18px">
            StyleBooth unifies textual and visual exemplar by mapping them into a same hid- den space making it possible to adjust the proportion of different styles in different modalities.
        </p>
        <img class="summary-img" src="./public/images/inter.jpg" style="width:100%;"><br><br>
          <p style="font-size: 18px">
            Compositional style editing combining 3 different styles. Both original image and the style exemplars are real world images. The art work "The Son of Man" by Rene Magritte is used as the original image and 3 exemplar images in different style are provided.
        </p>
        <img class="summary-img" src="./public/images/intersupp.jpg" style="width:100%;"><br><br>
      </div>

      <div class="content">
        <h2>BibTex</h2>
        <code>@InProceedings{Han_2025_ICCV,<br>
          &nbsp;&nbsp;title={StyleBooth: Image Style Editing with Multimodal Instruction},<br>
          &nbsp;&nbsp;author={Han, Zhen and Mao, Chaojie and Jiang, Zeyinzi and Pan, Yulin and Zhang, Jingfeng},<br>
          &nbsp;&nbsp;booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},<br>
          &nbsp;&nbsp;year={2025,<br>
          &nbsp;&nbsp;pages={1947-1957}<br>
          }
        </code>
      </div>

      <br><br>
      <footer class="footer">
        <div class="container">
          <div class="columns is-centered">
            <!-- <div class="content"> -->
              website template from <a href="https://dreambooth.github.io/">dreambooth</a>
            <!-- </div> -->
          </div>
        </div>
      </footer>
      <br><br>
  </body>
</html>
